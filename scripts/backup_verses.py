#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–µ–∫–∞–ø–∞ —Å—Ç–∏—Ö–æ–≤ Verse –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
import argparse
import gzip
import shutil

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(str(Path(__file__).parent.parent))
sys.path.append(str(Path(__file__).parent.parent / "python-parser"))

from database import DatabaseManager
from models import Verse


class VerseBackupManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –±–µ–∫–∞–ø–æ–≤ —Å—Ç–∏—Ö–æ–≤"""
    
    def __init__(self, backup_dir: str = "backups"):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
    
    async def create_backup(self, 
                          language: Optional[str] = None,
                          source: Optional[str] = None,
                          canto: Optional[int] = None,
                          compress: bool = True,
                          filename: Optional[str] = None) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –±–µ–∫–∞–ø —Å—Ç–∏—Ö–æ–≤
        
        Args:
            language: –§–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'ru', 'en')
            source: –§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'AI Generated', 'Bhagavad Gita')
            canto: –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞–Ω—Ç–æ (–¥–ª—è –®—Ä–∏–º–∞–¥ –ë—Ö–∞–≥–∞–≤–∞—Ç–∞–º)
            compress: –°–∂–∏–º–∞—Ç—å –ª–∏ –±–µ–∫–∞–ø
            filename: –ò–º—è —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –±–µ–∫–∞–ø–∞
        """
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –±–µ–∫–∞–ø–∞ —Å—Ç–∏—Ö–æ–≤...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filters = []
            if language:
                filters.append(f"lang_{language}")
            if source:
                filters.append(f"src_{source.replace(' ', '_')}")
            if canto:
                filters.append(f"canto_{canto}")
            
            filter_suffix = "_".join(filters) if filters else "all"
            filename = f"verses_backup_{timestamp}_{filter_suffix}.json"
        
        backup_path = self.backup_dir / filename
        
        async with DatabaseManager() as db:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∏—Ö–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
            verses = await db.get_verses_for_backup(
                language=language,
                source=source,
                canto=canto
            )
            
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(verses)} —Å—Ç–∏—Ö–æ–≤ –¥–ª—è –±–µ–∫–∞–ø–∞")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            backup_data = {
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "total_verses": len(verses),
                    "filters": {
                        "language": language,
                        "source": source,
                        "canto": canto
                    },
                    "version": "1.0"
                },
                "verses": []
            }
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∏—Ö–∏ –≤ —Å–ª–æ–≤–∞—Ä–∏
            for verse in verses:
                # verse —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                verse_dict = {
                    "id": verse["id"],
                    "sessionId": verse.get("sessionId"),
                    "chapter": verse["chapter"],
                    "verseNumber": verse["verseNumber"],
                    "sanskrit": verse["sanskrit"],
                    "translation": verse["translation"],
                    "commentary": verse.get("commentary"),
                    "assignedTo": verse.get("assignedTo"),
                    "isRead": verse.get("isRead", False),
                    "readAt": verse["readAt"].isoformat() if verse.get("readAt") else None,
                    "order": verse.get("order"),
                    "createdAt": verse["createdAt"].isoformat(),
                    "createdBy": verse.get("createdBy"),
                    "language": verse.get("language", "ru"),
                    "source": verse.get("source", "AI Generated"),
                    "title": verse["title"],
                    "transliteration": verse.get("transliteration"),
                    "updatedAt": verse["updatedAt"].isoformat(),
                    "wordByWordTranslation": verse.get("wordByWordTranslation"),
                    "isMergedVerse": verse.get("isMergedVerse", False),
                    "mergedWith": verse.get("mergedWith"),
                    "mergedBlockId": verse.get("mergedBlockId"),
                    "canto": verse.get("canto"),
                    "metadata": verse.get("metadata")
                }
                backup_data["verses"].append(verse_dict)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–µ–∫–∞–ø
            if compress:
                # –°–∂–∏–º–∞–µ–º —Ñ–∞–π–ª
                with gzip.open(f"{backup_path}.gz", 'wt', encoding='utf-8') as f:
                    json.dump(backup_data, f, ensure_ascii=False, indent=2)
                final_path = f"{backup_path}.gz"
            else:
                with open(backup_path, 'w', encoding='utf-8') as f:
                    json.dump(backup_data, f, ensure_ascii=False, indent=2)
                final_path = str(backup_path)
            
            print(f"‚úÖ –ë–µ–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {final_path}")
            print(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {self._get_file_size(final_path)}")
            
            return final_path
    
    async def restore_backup(self, backup_path: str, clear_existing: bool = False) -> int:
        """
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å—Ç–∏—Ö–∏ –∏–∑ –±–µ–∫–∞–ø–∞
        
        Args:
            backup_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–µ–∫–∞–ø–∞
            clear_existing: –û—á–∏—â–∞—Ç—å –ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–∏—Ö–∏ –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∏—Ö–æ–≤
        """
        print(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –±–µ–∫–∞–ø–∞: {backup_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(backup_path):
            raise FileNotFoundError(f"–§–∞–π–ª –±–µ–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {backup_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if backup_path.endswith('.gz'):
            with gzip.open(backup_path, 'rt', encoding='utf-8') as f:
                backup_data = json.load(f)
        else:
            with open(backup_path, 'r', encoding='utf-8') as f:
                backup_data = json.load(f)
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω –±–µ–∫–∞–ø –æ—Ç {backup_data['metadata']['created_at']}")
        print(f"üìñ –°—Ç–∏—Ö–æ–≤ –≤ –±–µ–∫–∞–ø–µ: {backup_data['metadata']['total_verses']}")
        
        async with DatabaseManager() as db:
            if clear_existing:
                print("üóëÔ∏è  –û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–∏—Ö–æ–≤...")
                await db.clear_verses()
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∏—Ö–∏
            restored_count = 0
            for verse_data in backup_data["verses"]:
                try:
                    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Verse
                    verse = Verse(
                        id=verse_data["id"],
                        sessionId=verse_data.get("sessionId"),
                        chapter=verse_data["chapter"],
                        verseNumber=verse_data["verseNumber"],
                        sanskrit=verse_data["sanskrit"],
                        translation=verse_data["translation"],
                        commentary=verse_data.get("commentary"),
                        assignedTo=verse_data.get("assignedTo"),
                        isRead=verse_data.get("isRead", False),
                        readAt=datetime.fromisoformat(verse_data["readAt"]) if verse_data.get("readAt") else None,
                        order=verse_data.get("order"),
                        createdAt=datetime.fromisoformat(verse_data["createdAt"]),
                        createdBy=verse_data.get("createdBy"),
                        language=verse_data.get("language", "ru"),
                        source=verse_data.get("source", "AI Generated"),
                        title=verse_data["title"],
                        transliteration=verse_data.get("transliteration"),
                        updatedAt=datetime.fromisoformat(verse_data["updatedAt"]),
                        wordByWordTranslation=verse_data.get("wordByWordTranslation"),
                        isMergedVerse=verse_data.get("isMergedVerse", False),
                        mergedWith=verse_data.get("mergedWith"),
                        mergedBlockId=verse_data.get("mergedBlockId"),
                        canto=verse_data.get("canto"),
                        metadata=verse_data.get("metadata")
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                    await db.save_verse(verse)
                    restored_count += 1
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç–∏—Ö–∞ {verse_data.get('id', 'unknown')}: {e}")
            
            print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {restored_count} —Å—Ç–∏—Ö–æ–≤")
            return restored_count
    
    async def list_backups(self) -> List[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±–µ–∫–∞–ø–æ–≤"""
        backups = []
        
        for file_path in self.backup_dir.glob("verses_backup_*.json*"):
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å–∂–∞—Ç –ª–∏ —Ñ–∞–π–ª
                is_compressed = file_path.suffix == '.gz'
                file_to_read = file_path
                
                if is_compressed:
                    # –î–ª—è —Å–∂–∞—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ —á–∏—Ç–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    with gzip.open(file_path, 'rt', encoding='utf-8') as f:
                        data = json.load(f)
                else:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                
                backup_info = {
                    "filename": file_path.name,
                    "path": str(file_path),
                    "size": self._get_file_size(str(file_path)),
                    "created_at": data["metadata"]["created_at"],
                    "total_verses": data["metadata"]["total_verses"],
                    "filters": data["metadata"]["filters"],
                    "is_compressed": is_compressed
                }
                backups.append(backup_info)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –±–µ–∫–∞–ø–∞ {file_path}: {e}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        backups.sort(key=lambda x: x["created_at"], reverse=True)
        return backups
    
    def _get_file_size(self, file_path: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        size = os.path.getsize(file_path)
        
        if size < 1024:
            return f"{size} B"
        elif size < 1024 * 1024:
            return f"{size / 1024:.1f} KB"
        elif size < 1024 * 1024 * 1024:
            return f"{size / (1024 * 1024):.1f} MB"
        else:
            return f"{size / (1024 * 1024 * 1024):.1f} GB"


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ú–µ–Ω–µ–¥–∂–µ—Ä –±–µ–∫–∞–ø–æ–≤ —Å—Ç–∏—Ö–æ–≤ Verse')
    parser.add_argument('action', choices=['create', 'restore', 'list'],
                       help='–î–µ–π—Å—Ç–≤–∏–µ: create (—Å–æ–∑–¥–∞—Ç—å), restore (–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å), list (—Å–ø–∏—Å–æ–∫)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–µ–∫–∞–ø–∞
    parser.add_argument('--language', '-l', 
                       help='–§–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É (ru, en, etc.)')
    parser.add_argument('--source', '-s',
                       help='–§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É (AI Generated, Bhagavad Gita, etc.)')
    parser.add_argument('--canto', '-c', type=int,
                       help='–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞–Ω—Ç–æ (–¥–ª—è –®—Ä–∏–º–∞–¥ –ë—Ö–∞–≥–∞–≤–∞—Ç–∞–º)')
    parser.add_argument('--no-compress', action='store_true',
                       help='–ù–µ —Å–∂–∏–º–∞—Ç—å –±–µ–∫–∞–ø')
    parser.add_argument('--filename', '-f',
                       help='–ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∫–∞–ø–∞')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
    parser.add_argument('--backup-file', '-b',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–µ–∫–∞–ø–∞ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è')
    parser.add_argument('--clear-existing', action='store_true',
                       help='–û—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–∏—Ö–∏ –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º')
    
    args = parser.parse_args()
    
    backup_manager = VerseBackupManager()
    
    try:
        if args.action == 'create':
            backup_path = await backup_manager.create_backup(
                language=args.language,
                source=args.source,
                canto=args.canto,
                compress=not args.no_compress,
                filename=args.filename
            )
            print(f"üéâ –ë–µ–∫–∞–ø —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {backup_path}")
            
        elif args.action == 'restore':
            if not args.backup_file:
                print("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Ñ–∞–π–ª –±–µ–∫–∞–ø–∞ —Å –ø–æ–º–æ—â—å—é --backup-file")
                return
            
            restored_count = await backup_manager.restore_backup(
                args.backup_file,
                clear_existing=args.clear_existing
            )
            print(f"üéâ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {restored_count} —Å—Ç–∏—Ö–æ–≤")
            
        elif args.action == 'list':
            backups = await backup_manager.list_backups()
            
            if not backups:
                print("üìÅ –ë–µ–∫–∞–ø—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return
            
            print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(backups)} –±–µ–∫–∞–ø–æ–≤:")
            print()
            
            for backup in backups:
                print(f"üìÑ {backup['filename']}")
                print(f"   üìÖ –°–æ–∑–¥–∞–Ω: {backup['created_at']}")
                print(f"   üìä –°—Ç–∏—Ö–æ–≤: {backup['total_verses']}")
                print(f"   üíæ –†–∞–∑–º–µ—Ä: {backup['size']}")
                print(f"   üóúÔ∏è  –°–∂–∞—Ç: {'–î–∞' if backup['is_compressed'] else '–ù–µ—Ç'}")
                
                filters = backup['filters']
                if any(filters.values()):
                    print(f"   üîç –§–∏–ª—å—Ç—Ä—ã:")
                    for key, value in filters.items():
                        if value:
                            print(f"      {key}: {value}")
                print()
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
